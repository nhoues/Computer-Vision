{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "challenge_2 (1).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bF5TlBH5I_q9"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF5TlBH5I_q9",
        "colab_type": "text"
      },
      "source": [
        "# Download Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT6NYcpHZjkh",
        "colab_type": "code",
        "outputId": "6a7ce08a-2925-45eb-d877-1702c0eaf6a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRKc4dfNVs2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests  \n",
        "file_url = \"https://zindpublic.blob.core.windows.net/private/uploads/competition_datafile/file/285/train.zip?sp=r&sv=2015-04-05&sr=b&st=2020-03-18T00%3A52%3A16Z&se=2020-03-18T01%3A08%3A16Z&sig=oM5J80LyAgyNZ1nUUpdisLFaQkToTggD612qxbjyCkE%3D\"\n",
        "    \n",
        "r = requests.get(file_url, stream = True)  \n",
        "  \n",
        "with open(\"/content/drive/My Drive/Zindi problems /Third/train.zip\", \"wb\") as file:  \n",
        "    for block in r.iter_content(chunk_size = 1024): \n",
        "         if block:  \n",
        "             file.write(block)  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl_wUtX1Yxw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests  \n",
        "file_url = \"https://zindpublic.blob.core.windows.net/private/uploads/competition_datafile/file/283/test.zip?sp=r&sv=2015-04-05&sr=b&st=2020-03-18T00%3A53%3A28Z&se=2020-03-18T01%3A09%3A28Z&sig=PD5h6j8Val45QyZ6ULo%2BEuI8Je2Bdgdci3%2Ffdj9oZuI%3D\"\n",
        "    \n",
        "r = requests.get(file_url, stream = True)  \n",
        "  \n",
        "with open(\"/content/drive/My Drive/Zindi problems /Third/test.zip\", \"wb\") as file:  \n",
        "    for block in r.iter_content(chunk_size = 1024): \n",
        "         if block:  \n",
        "             file.write(block)  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf6l1dktZKJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Zindi problems /Third')  #change dir\n",
        "\n",
        "\n",
        "!unzip train.zip\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWPBnFXzZm7f",
        "colab_type": "text"
      },
      "source": [
        "# Impotation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85qrNpWuKAjo",
        "colab_type": "code",
        "outputId": "0f275ec9-75de-401a-b4dd-72a7c9757255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        }
      },
      "source": [
        "# Install Pytorch libraries \n",
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "!pip3 install torchvision\n",
        "!pip3 install albumentations"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.3.0.post4\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl (592.3MB)\n",
            "\u001b[K     |████████████████████████████████| 592.3MB 1.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.18.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.13)\n",
            "\u001b[31mERROR: torchvision 0.5.0 has requirement torch==1.4.0, but you'll have torch 0.3.0.post4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.60 has requirement torch>=1.0.0, but you'll have torch 0.3.0.post4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.4.0\n",
            "    Uninstalling torch-1.4.0:\n",
            "      Successfully uninstalled torch-1.4.0\n",
            "Successfully installed torch-0.3.0.post4\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.2)\n",
            "Collecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 9.2kB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 0.3.0.post4\n",
            "    Uninstalling torch-0.3.0.post4:\n",
            "      Successfully uninstalled torch-0.3.0.post4\n",
            "Successfully installed torch-1.4.0\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.6/dist-packages (0.1.12)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from albumentations) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.18.2)\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 24.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.16.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.12.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.2.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.1.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (7.0.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (46.0.0)\n",
            "Building wheels for collected packages: imgaug\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654020 sha256=38fa9455c2fe2fb0e61e6f696801abf7975c5106ee3226374ebabee376c62442\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built imgaug\n",
            "Installing collected packages: imgaug\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "Successfully installed imgaug-0.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvUvKLDwJ1Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing Numpy Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "#import torch.utils.data as data\n",
        "#from torch.utils.data import Dataset\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import  google.colab  \n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import warnings  \n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmkAuMSkZ5Y2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "target = ['healthy_wheat','leaf_rust','stem_rust']\n",
        "train = pd.DataFrame()\n",
        "for i in target : \n",
        "  a= pd.DataFrame()\n",
        "  a['im_name'] = os.listdir('/content/drive/My Drive/Zindi problems /Third/Train/'+i) \n",
        "  a['name']=a['im_name'].str.extract(r'(?P<name>\\w*).\\w*')\n",
        "  a['target'] = i\n",
        "  train = train.append(a,ignore_index = True)\n",
        "a = pd.get_dummies(train['target'])\n",
        "for i in target : \n",
        "  train[i] = a[i]\n",
        "train['im_path'] = '/content/drive/My Drive/Zindi problems /Third/Train/'+train['target']+'/'+train['im_name']\n",
        " \n",
        "from sklearn import preprocessing \n",
        "label_encoder = preprocessing.LabelEncoder() \n",
        "\n",
        "train['label']= label_encoder.fit_transform(train['target']) \n",
        "  \n",
        "train.to_csv(\"/content/drive/My Drive/Zindi problems /Third/train.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NkL2E-Samfu",
        "colab_type": "code",
        "outputId": "7a5f15fe-816e-4b55-9e1d-ca4624453adf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Zindi problems /Third/train.csv\")\n",
        "df[\"kfold\"] = -1\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X=df, y=df.target.values)):\n",
        "  print(len(train_idx), len(val_idx))\n",
        "  df.loc[val_idx, 'kfold'] = fold\n",
        "    \n",
        "df.to_csv(\"/content/drive/My Drive/Zindi problems /Third/train_folds.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "700 175\n",
            "700 175\n",
            "700 175\n",
            "700 175\n",
            "700 175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yn2BasnRtDJ",
        "colab_type": "text"
      },
      "source": [
        "# Data_set_class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jweft9-QQorA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DatasetTrain : \n",
        "    def __init__(self, folds,img_height=512,img_width=512,mean=(0.485,0.456,0.405),std=(0.229,0.224,0.225)) : \n",
        "    \n",
        "        df = pd.read_csv(\"/content/drive/My Drive/Zindi problems /Third/train_folds.csv\")\n",
        "        df = df[df.kfold.isin(folds)].reset_index(drop=True) \n",
        "        self.df = df\n",
        "        self.image_ids = df['im_path'].values \n",
        "        self.labels = df.label \n",
        "        if len(folds)==1 : \n",
        "          self.aug = A.Compose([A.Resize(img_height,img_width)\n",
        "                                ,A.Normalize(mean,std,always_apply=True)])\n",
        "        else :     \n",
        "          self.aug = A.Compose([A.Resize(img_height,img_width)\n",
        "                                        ,A.ShiftScaleRotate(shift_limit=0.0625,scale_limit=0.1,rotate_limit=5,p=0.9)\n",
        "                                        ,A.Normalize(mean,std,always_apply=True)\n",
        "                                         ])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # print(image_src)\n",
        "        image = Image.open(f\"{self.image_ids[idx]}\")\n",
        "        image = self.aug(image= np.array(image))['image']\n",
        "        image = np.transpose(image,(2,0,1)).astype(float)\n",
        " \n",
        "\n",
        "        return { 'img' :torch.tensor(image,dtype = torch.float),\n",
        "                  'target' : torch.tensor(self.labels[idx],dtype = torch.long) } "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_efwmfJTm0E",
        "colab_type": "code",
        "outputId": "72724bce-ebe6-44cf-ea75-73caf1383364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "data = DatasetTrain(folds=VALIDATION_FOLDS[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0359c474aee1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALIDATION_FOLDS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'VALIDATION_FOLDS' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKM6hYxOTscA",
        "colab_type": "code",
        "outputId": "c7ce1758-ea81-4a51-f08b-97b245811d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "idx = 6\n",
        "img = data[idx]['img']\n",
        "npimg = img.numpy() \n",
        "plt.imshow(np.transpose(npimg,(1,2,0)))\n",
        "data[idx]['target']\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-230dca16c7ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnpimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG8rvraqUiN_",
        "colab_type": "text"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph7gl32Vpjqv",
        "colab_type": "code",
        "outputId": "482c85b5-de77-454c-d382-8b073d8dfa0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "source": [
        "!pip install pretrainedmodels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pretrainedmodels\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30kB 36.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40kB 40.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51kB 38.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (1.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (0.5.0)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (4.38.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (1.18.2)\n",
            "Building wheels for collected packages: pretrainedmodels\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp36-none-any.whl size=60962 sha256=2749b1a6286704cad34c9ebfc053f1283f59c125332fd90a53e39d76ed2f6d91\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n",
            "Successfully built pretrainedmodels\n",
            "Installing collected packages: munch, pretrainedmodels\n",
            "Successfully installed munch-2.5.0 pretrainedmodels-0.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygw0-D87TtOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import pretrainedmodels \n",
        "import torch.nn as nn \n",
        "from torch.nn import functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UU4fUKUVClx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet101(nn.Module) : \n",
        "  def __init__(self,pretrained) : \n",
        "    super(ResNet101,self).__init__() \n",
        "    if pretrained is True : \n",
        "      self.model = pretrainedmodels.__dict__['resnet101'](pretrained = 'imagenet') \n",
        "    else : \n",
        "      self.model = pretrainedmodels.__dict__['resnet101'](pretrained = None) \n",
        "      \n",
        "    self.drop = nn.Dropout(p=0.4, inplace=False)\n",
        "    self.l0 = nn.Linear(2048,3) \n",
        "  def forward(self,x) : \n",
        "    bs,_,_,_ = x.shape\n",
        "    x = self.model.features(x) \n",
        "    x = F.adaptive_avg_pool2d(x,1).reshape(bs,-1)\n",
        "    x = self.drop(x)\n",
        "    l0 = self.l0(x)\n",
        "\n",
        "    return l0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab71URjgVMLd",
        "colab_type": "text"
      },
      "source": [
        "# Train the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRWizaDFjZEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_fn(outputs,targets) : \n",
        "  return nn.CrossEntropyLoss()(outputs,targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCyNIVbDqdjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate (dataset,data_loader,model) : \n",
        "  with torch.no_grad():\n",
        "    model.to(DEVICE)\n",
        "   \n",
        "    model.eval() \n",
        "    final_loss = 0\n",
        "    counter = 0 \n",
        "\n",
        "    for bi,d in tqdm(enumerate(data_loader),total = len(data_loader)):\n",
        "      counter = counter + 1 \n",
        "      img = d['img']\n",
        "      labels=d['target']\n",
        "      \n",
        "      img =img.to(DEVICE,dtype=torch.float)\n",
        "      labels=labels.to(DEVICE,dtype=torch.long )\n",
        "\n",
        "\n",
        "      outputs =model(img) \n",
        "\n",
        "      loss = loss_fn(outputs, labels)\n",
        "      val_loss += loss\n",
        "    print('val_loss= ' , (val_loss / counter).item())\n",
        "    return val_loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl7FghIvqczw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train (dataset,data_loader,model,optimizer) : \n",
        "  model.train() \n",
        "  final_loss=0\n",
        "  counter = 0 \n",
        "  for bi,d in tqdm(enumerate(data_loader),total = len(data_loader)):\n",
        "    counter = counter + 1 \n",
        "    img = d['img']\n",
        "    labels=d['target']\n",
        "    \n",
        "    \n",
        "    img =img.to(DEVICE,dtype=torch.float)\n",
        "    labels=labels.to(DEVICE,dtype=torch.long )\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs =model(img) \n",
        "\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    final_loss+= loss \n",
        "    optimizer.step()\n",
        "  print('train_loss= ',(final_loss/counter).item())\n",
        "  return final_loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OafYOpvXU5O4",
        "colab_type": "text"
      },
      "source": [
        "#tuning for good model an parmeters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtRRmRinotvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device ='cuda'\n",
        "CUDA_VISIBLE_DEVICES =0\n",
        "N_EPOCHS = 20\n",
        "DEVICE ='cuda'\n",
        "TRAIN_BATCH_SIZE = 6\n",
        "VAL_BATCH_SIZE = 2\n",
        "TRAINING_FOLDS  = [(0,1,2,3),(0,4,2,3),(0,1,4,3),(2,1,4,3),(0,1,4,2)]\n",
        "VALIDATION_FOLDS =((4,),(1,),(2,),(0,),(3,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWLfqp8FU49o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run(model,EPOCHS,i,save=False) : \n",
        "  \n",
        "  train_dataset = DatasetTrain(folds=TRAINING_FOLDS[i])\n",
        "  train_loder = torch.utils.data.DataLoader(\n",
        "    dataset = train_dataset , \n",
        "    batch_size = TRAIN_BATCH_SIZE,\n",
        "    shuffle = True , \n",
        "    num_workers = 4\n",
        ")\n",
        "  valid_dataset = DatasetTrain(folds=VALIDATION_FOLDS[i])\n",
        "  valid_loder = torch.utils.data.DataLoader(\n",
        "    dataset = valid_dataset , \n",
        "    batch_size = VAL_BATCH_SIZE,\n",
        "    shuffle = False , \n",
        "    num_workers = 4\n",
        ") \n",
        "  optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='max',patience= 5,factor=0.3,verbose=True )\n",
        "  best_val=1000\n",
        "  if torch.cuda.device_count()> 1 : \n",
        "    model = nn.DataParallel(model)\n",
        "  getattr(tqdm, '_instances', {}).clear()\n",
        "  train_loss=[] \n",
        "  val_loss=[]\n",
        "  train_fold_results = []\n",
        "  for epoch in range(EPOCHS) : \n",
        "    print(epoch)\n",
        "    tr_loss=train(train_dataset,train_loder,model,optimizer)\n",
        " \n",
        "    val_loss =evaluate(valid_dataset,valid_loder,model)\n",
        " \n",
        "\n",
        "    scheduler.step(val_loss) \n",
        "    google.colab.output.eval_js('new Audio(\"http://soundbible.com/grab.php?id=1815&type=mp3\").play()')\n",
        "    train_fold_results.append({\n",
        "            'fold': i,\n",
        "            'epoch': epoch,\n",
        "            'train_loss': tr_loss / len(train_loder),\n",
        "            'valid_loss': val_loss / len(valid_loder),\n",
        "           \n",
        "        })\n",
        "    if (val_loss < best_val) and (save==True) :  \n",
        "      torch.save(model.state_dict(),f\"/content/drive/My Drive/Zindi problems /Third/model_{i}.bin\")  \n",
        "      best_val=val_score.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp-3o-hBVc7Z",
        "colab_type": "code",
        "outputId": "ea154b69-a020-40bf-bdae-7ead0a7c2ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model = ResNet101(True)\n",
        "model = model.to('cuda')\n",
        "run(model,25,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e6d7c013f30d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet101\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 7.43 GiB total capacity; 6.90 GiB already allocated; 2.94 MiB free; 6.91 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFxmJBhWlhZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds = None\n",
        "\n",
        "    for step, batch in enumerate(dataloader_test):\n",
        "\n",
        "        images = batch[0]\n",
        "        images = images.to(device, dtype=torch.float)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "\n",
        "            if test_preds is None:\n",
        "                test_preds = outputs.data.cpu()\n",
        "            else:\n",
        "                test_preds = torch.cat((test_preds, outputs.data.cpu()), dim=0)\n",
        "    \n",
        "    \n",
        "    # Save predictions per fold\n",
        "    submission_df[['healthy', 'multiple_diseases', 'rust', 'scab']] = torch.softmax(test_preds, dim=1)\n",
        "    submission_df.to_csv('submission_fold_{}.csv'.format(i_fold), index=False)\n",
        "\n",
        "    # logits avg\n",
        "    if submissions is None:\n",
        "        submissions = test_preds / N_FOLDS\n",
        "    else:\n",
        "        submissions += test_preds / N_FOLDS\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjWyvsBgWmb1",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAhAgf0jWl8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1A4DLUQVZHD",
        "colab_type": "text"
      },
      "source": [
        "# creat folds model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vj43mIcXzVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in  range(len(TRAINING_FOLDS)) :\n",
        "  print('folds number = ',i)\n",
        "  model = ResNet101(True)\n",
        "  model = model.to('cuda')\n",
        "  run(model,EPOCHS,i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQYS9pUvUuFS",
        "colab_type": "text"
      },
      "source": [
        "# Make submission "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IswK3VhQhsKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "test = pd.DataFrame()\n",
        "test['index']=os.listdir('/content/drive/My Drive/Zindi problems /Third/test') \n",
        "test.to_csv('test.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tedudUU_hkmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DatasetTest : \n",
        "  def __init__(self,df,img_height=1024,img_width=1024,mean=(0.485,0.456,0.405),std=(0.229,0.224,0.225)) : \n",
        "    \n",
        "    self.image_ids = df['index'].values \n",
        "    self.aug = albumentations.Compose([albumentations.Resize(img_height,img_width)\n",
        "                                        ,albumentations.Normalize(mean,std,always_apply=True)\n",
        "                                         ]) \n",
        "\n",
        "  def __len__(self) : \n",
        "    return (len(self.image_ids)) \n",
        "  def __getitem__(self,item) : \n",
        "    image = Image.open(f\"/content/drive/My Drive/Zindi problems /Third/test/{self.image_ids[item]}\")\n",
        "    image = self.aug(image= np.array(image))['image']\n",
        "    image = np.transpose(image,(2,0,1)).astype(float)\n",
        "    return {  'image' : torch.tensor(image,dtype = torch.float),\n",
        "              'img_index' : self.image_ids[item]\n",
        "            }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMWFKkf5nFFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = DatasetTest(test)\n",
        "import matplotlib.pyplot as plt \n",
        "idx = 10\n",
        "img = data[idx]['image']\n",
        "for predictor, coef in predictors:\n",
        "        out = predictor(img)\n",
        "npimg = img.numpy() \n",
        "plt.imshow(np.transpose(npimg,(1,2,0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI-Q7PscWdFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictors = []\n",
        "\n",
        "for i, (model_path, net, coef) in enumerate([\n",
        "    ('/content/drive/My Drive/Zindi problems /Third/model_0.bin', ResNet101(False), 0.2),\n",
        "    ('/content/drive/My Drive/Zindi problems /Third/model_1.bin', ResNet101(False), 0.2),\n",
        "    ('/content/drive/My Drive/Zindi problems /Third/model_2.bin', ResNet101(False), 0.2),\n",
        "    ('/content/drive/My Drive/Zindi problems /Third/model_3.bin', ResNet101(False), 0.2),\n",
        "    ('/content/drive/My Drive/Zindi problems /Third/model_4.bin', ResNet101(False), 0.2)\n",
        "]): \n",
        "    MODEL = net\n",
        "    MODEL.load_state_dict(torch.load(model_path))\n",
        "    MODEL.to('cuda')\n",
        "    MODEL.eval()\n",
        "    print('model ',i,' is ready')\n",
        "    predictors.append((MODEL, coef))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzwbQP-Ek6OH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE ='cuda'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwLzvHlDWhl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_prediction(image):\n",
        "    healthy_wheat =0\n",
        "    leaf_rust =0\n",
        "    stem_rust=0\n",
        "    for predictor, coef in predictors:\n",
        "        out = predictor(image)\n",
        "        healthy_wheat =healthy_wheat +(out[0])* coef\n",
        "        leaf_rust = leaf_rust +(out[1])* coef\n",
        "        stem_rust = stem_rust + (out[2])* coef \n",
        "    return healthy_wheat,leaf_rust,stem_rust"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFfZMjjvlQZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SequentialSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i50qjxwnWkCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "row_id = []\n",
        "healthy_wheat =[]\n",
        "leaf_rust =[]\n",
        "stem_rust=[]\n",
        "data = pd.read_csv('test.csv')\n",
        "dataset = DatasetTest(data)\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset = dataset , \n",
        "    batch_size = 1,\n",
        "    shuffle = False , \n",
        "    num_workers = 4\n",
        ") \n",
        "for bi,d in tqdm(enumerate(data_loader),total = int(len(dataset)/data_loader.batch_size)):\n",
        "  \n",
        "  img = d['image']\n",
        "  image_ids =d['img_index']\n",
        "  img =img.to(DEVICE,dtype=torch.float)\n",
        "  healthys,leafs,stems=make_prediction(img)\n",
        "  for image_id, healthy,leaf,stem in zip(image_ids, healthys,leafs,stems):\n",
        "    row_id.append(image_id)\n",
        "    healthy_wheat.append(healthy)\n",
        "    leaf_rust.append(leaf)        \n",
        "    stem_rust.append(stem)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2zC1PNoXHOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.read_csv('sample_submission (1).csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH3I7x2bXGgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df_submission = pd.DataFrame(\n",
        "    {\n",
        "        'row_id': row_id,\n",
        "        'target': target\n",
        "    },\n",
        "    columns=['row_id','target']\n",
        ")\n",
        "\n",
        "df_submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "df_submission.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7k8U6veoS0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = torch.tensor([[0,1,0,1,0,0]], dtype=torch.float32)\n",
        "output = torch.randn(1, 6, requires_grad=True)\n",
        "weights = torch.tensor([0.16, 0.16, 0.25, 0.25, 0.083, 0.083])\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
        "loss = criterion(output, target)\n",
        "loss = (loss * weights).mean()\n",
        "loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go_xnPv9oTZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " a = torch.tensor([1])\n",
        " b = torch.tensor([1])\n",
        " nn.CrossEntropyLoss()(a,b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaGD6cX-6cm5",
        "colab_type": "code",
        "outputId": "e5207167-f67f-4cfc-cf35-8fe8406adad5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=37a28ff3ea6f5376c23d497a33b762367ac750de1ee5128ed0e581e938ef1bce\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 10.7 GB  | Proc size: 3.3 GB\n",
            "GPU RAM Free: 2MB | Used: 7609MB | Util 100% | Total 7611MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3Xuzi9uaGDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaNsJ9gBaLlP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}